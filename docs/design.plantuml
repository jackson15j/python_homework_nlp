@startuml design
title NLP Homework Design

!pragma useNewPackage
set separator .


package App {
        package common {
                class Content {
                        file_name : str
                        original_content : str
                        original_sentences : list[str]
                        original_tokens : list[list[str]]
                        filtered_tokens : list[list[str]]
                        filtered_collections_counters : list[collections.Counter]
                        filtered_collections_counter_total : collections.Counter
                }
        }
        package NlpParser {
                entity main {
                        +cli_parser()
                        +workflow()
                        +main()
                }
                entity FileReader
                class Normaliser {
                        +normalise()
                }
                class Counter {
                        +counter()
                }
        }
        package Renderers {
                interface BaseRenderer #line.dotted {
                        rendered_output
                        +render()
                        +write_to_file()
                }
                class ConsoleRenderer
                class CsvRenderer
                class JsonRenderer
                class HtmlRenderer
                class MarkdownRenderer
        }
}

Content *-[dotted]- FileReader
Content *-[dotted]- Normaliser
Content *-[dotted]- Counter
main::main -right->"1" FileReader
main::workflow -->"2" Normaliser
main::workflow -->"3" Counter
main::workflow -->"4" ConsoleRenderer
main::workflow -->"4" CsvRenderer
main::workflow -->"4" HtmlRenderer
main::workflow -->"4" JsonRenderer
BaseRenderer <|-[dotted]- ConsoleRenderer
BaseRenderer <|-[dotted]- CsvRenderer
BaseRenderer <|-[dotted]- HtmlRenderer
BaseRenderer <|-[dotted]- JsonRenderer
BaseRenderer <|-[dotted]- MarkdownRenderer
FileReader -[hidden]left-> Normaliser
Normaliser -[hidden]left-> Counter


note top of Content
        - Instance created per-file.
        - Passed by-Reference through the App.
end note

note top of main
        ``cli_parser()``:

        - ``-d,--docs_dir`` - Default: ``test_docs/``.
        - ``-n,--num_most_common_words`` - Default: Infinite.

        ``workflow()``:
        - Input: ``list[Content]``
        - Calls: ``Normaliser.normalise()``
        - Calls: ``Counter.counter()`
end note

note bottom of FileReader
        - Input: Folder of text files.
        - Output: ``list[Content]``.
end note

note bottom of Normaliser
        Function for each step:

        - Tokenize file into sentences.
        - Tokenize sentences into words.
        - Stem tokens.
        - Remove *"stop"* words
        - <b>TODO:</b> Expand contractions.
end note

note bottom of Counter
        Count of each unique word with file/sentence recorded.
end note

note bottom of ConsoleRenderer
        CLI flag: ``--output_to_console`` to enable.
end note

note bottom of CsvRenderer
        Input JSON:
        ```
        {
            <word>: {
                "count": <int>,
                "matches": [<original_sentence>, ...],
                "files": [<filename>, ...],
                },
            },
        }
        ```
end note
@enduml
